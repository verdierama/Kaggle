{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-04T15:00:50.893853Z",
     "iopub.status.busy": "2025-03-04T15:00:50.893591Z",
     "iopub.status.idle": "2025-03-04T15:00:52.257008Z",
     "shell.execute_reply": "2025-03-04T15:00:52.255847Z",
     "shell.execute_reply.started": "2025-03-04T15:00:50.893828Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Detect my accelerator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T15:00:52.258480Z",
     "iopub.status.busy": "2025-03-04T15:00:52.258059Z",
     "iopub.status.idle": "2025-03-04T15:01:07.362297Z",
     "shell.execute_reply": "2025-03-04T15:01:07.361386Z",
     "shell.execute_reply.started": "2025-03-04T15:00:52.258454Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version de TensorFlow : 2.11.0\n",
      "GPUs disponibles : []\n",
      "CUDA supporté : False\n",
      "GPU détecté : []\n",
      "Version de CUDA utilisée par TensorFlow : Inconnu\n",
      "Version de cuDNN : Inconnu\n",
      "CUDA supporté : False\n",
      "GPU détecté : []\n",
      "CUDA supporté : False\n",
      "Running on CPU.\n",
      "REPLICAS: 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Detect hardware, return appropriate distribution strategy\n",
    "print(\"Version de TensorFlow :\", tf.__version__)\n",
    "\n",
    "try:\n",
    "    # Try to detect a TPU\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # Detect TPU\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    print(\"Running on TPU:\", tpu.master())\n",
    "\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "    gpus = tf.config.list_physical_devices('GPU')  # Check for available GPUs\n",
    "\n",
    "    print(\"GPUs disponibles :\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "    # Vérifie si TensorFlow est compilé avec CUDA\n",
    "    print(\"CUDA supporté :\", tf.test.is_built_with_cuda())\n",
    "\n",
    "    # Vérifie si TensorFlow est compilé avec cuDNN\n",
    "    print(\"cuDNN supporté :\", tf.test.is_built_with_cudnn())\n",
    "\n",
    "    # Affiche les dispositifs physiques disponibles (GPU)\n",
    "    print(\"GPU détecté :\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "    \n",
    "    # Vérifier la version de CUDA utilisée par TensorFlow\n",
    "    print(\"Version de CUDA utilisée par TensorFlow :\", tf.sysconfig.get_build_info().get(\"cuda_version\", \"Inconnu\"))\n",
    "    # Vérifier la version de cuDNN\n",
    "    print(\"Version de cuDNN :\", tf.sysconfig.get_build_info().get(\"cudnn_version\", \"Inconnu\"))\n",
    "    from tensorflow.python.platform import build_info\n",
    "    #print(\"Version de cuDNN utilisée par TensorFlow :\", build_info.cudnn_version)\n",
    "    print(\"CUDA supporté :\", tf.test.is_built_with_cuda())\n",
    "    #print(\"cuDNN supporté :\", tf.test.is_built_with_cudnn())\n",
    "\n",
    "\n",
    "    print(\"GPU détecté :\", tf.config.list_physical_devices('GPU'))\n",
    "    print(\"CUDA supporté :\", tf.test.is_built_with_cuda())\n",
    "    #print(\"cuDNN supporté :\", tf.test.is_built_with_cudnn())\n",
    "\n",
    "    from tensorflow.python.platform import build_info\n",
    "    #print(\"Version de cuDNN utilisée par TensorFlow :\", build_info.cudnn_version)\n",
    "    \n",
    "    if gpus:\n",
    "        strategy = tf.distribute.MirroredStrategy()  # Multi-GPU / Single-GPU strategy\n",
    "        print(f\"Running on {len(gpus)} GPU(s).\")\n",
    "    else:\n",
    "        strategy = tf.distribute.get_strategy()  # Default strategy (CPU fallback)\n",
    "        print(\"Running on CPU.\")\n",
    "\n",
    "print(\"REPLICAS:\", strategy.num_replicas_in_sync)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T15:01:07.363861Z",
     "iopub.status.busy": "2025-03-04T15:01:07.363222Z",
     "iopub.status.idle": "2025-03-04T15:01:07.821804Z",
     "shell.execute_reply": "2025-03-04T15:01:07.820601Z",
     "shell.execute_reply.started": "2025-03-04T15:01:07.363825Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Extraire et enregistrer l\\'image dans un fichier JPEG\\nfor parsed_record in parsed_dataset.take(1):  # Prendre un exemple\\n    img_bytes = parsed_record[\"image\"].numpy()  # Récupérer l\\'image sous forme de bytes\\n    \\n    # Décoder l\\'image en tableau numpy\\n    img_array = cv2.imdecode(np.frombuffer(img_bytes, np.uint8), cv2.IMREAD_COLOR)\\n\\n    # Enregistrer l\\'image décodée au format JPEG\\n    output_image_path = \"output_image.jpg\"  # Chemin du fichier de sortie\\n    cv2.imwrite(output_image_path, img_array)  # Sauvegarde en JPEG\\n\\n    # Afficher l\\'image avec matplotlib\\n    plt.imshow(cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB))  # Convertir BGR (OpenCV) en RGB (Matplotlib)\\n    plt.axis(\\'off\\')  # Désactiver les axes\\n    plt.show()\\n\\n    print(f\"L\\'image a été enregistrée sous {output_image_path}\")\\n    '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Fonction de parsing\n",
    "def _parse_function(proto):\n",
    "    features = {\n",
    "        \"id\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string)  # Remplace \"image_raw\" par \"image\"\n",
    "    }\n",
    "    return tf.io.parse_single_example(proto, features)\n",
    "\n",
    "# Charger et parser les données\n",
    "raw_dataset = tf.data.TFRecordDataset(\"../input/tpu-getting-started/tfrecords-jpeg-224x224/train/00-224x224-798.tfrec\")\n",
    "\n",
    "# Appliquer le parsing\n",
    "parsed_dataset = raw_dataset.map(_parse_function)\n",
    "\"\"\"\n",
    "# Extraire et enregistrer l'image dans un fichier JPEG\n",
    "for parsed_record in parsed_dataset.take(1):  # Prendre un exemple\n",
    "    img_bytes = parsed_record[\"image\"].numpy()  # Récupérer l'image sous forme de bytes\n",
    "    \n",
    "    # Décoder l'image en tableau numpy\n",
    "    img_array = cv2.imdecode(np.frombuffer(img_bytes, np.uint8), cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Enregistrer l'image décodée au format JPEG\n",
    "    output_image_path = \"output_image.jpg\"  # Chemin du fichier de sortie\n",
    "    cv2.imwrite(output_image_path, img_array)  # Sauvegarde en JPEG\n",
    "\n",
    "    # Afficher l'image avec matplotlib\n",
    "    plt.imshow(cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB))  # Convertir BGR (OpenCV) en RGB (Matplotlib)\n",
    "    plt.axis('off')  # Désactiver les axes\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"L'image a été enregistrée sous {output_image_path}\")\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 1243559,
     "sourceId": 21154,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
